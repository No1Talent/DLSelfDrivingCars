{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/No1Talent/DLSelfDrivingCars/blob/master/Self_Driving_Car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "vP8hiq1ObRoi"
      }
    },
    {
      "metadata": {
        "id": "2BHPjDjuRYQK",
        "outputId": "01c475ff-65ce-4e08-a9ad-fe8429ce5b84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets # handling deep learning models, image transformations, and datasets\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ],
      "metadata": {
        "id": "pyYtIU_3f5Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Import\n",
        "\n",
        "```\n",
        "# download and unzip\n",
        "!wget https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip\n",
        "!unzip data.zip\n",
        "%ls\n",
        "\n",
        "# remove unnecessary\n",
        "!rm data.zip\n",
        "!rm -r __MACOSX\n",
        "\n",
        "# save data to MyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mv data \"/content/drive/MyDrive/\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "nRWqFadFdxhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/')\n",
        "\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "gkSL2AscdCao",
        "outputId": "9587b17f-19ad-4ecb-ecde-cc3873b9ef62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "LVVRptHQRlmz"
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "samples = []\n",
        "with open('data/driving_log.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader, None)\n",
        "    for line in reader:\n",
        "        samples.append(line)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_len = int(0.8 * len(samples))\n",
        "train_samples, validation_samples = random_split(samples, [train_len, len(samples) - train_len])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples.head\n",
        "len(samples), samples[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MeYgSBEfBtR",
        "outputId": "9c918e32-323b-4b78-9037-967087126bb3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8036,\n",
              " [['IMG/center_2016_12_01_13_30_48_287.jpg',\n",
              "   ' IMG/left_2016_12_01_13_30_48_287.jpg',\n",
              "   ' IMG/right_2016_12_01_13_30_48_287.jpg',\n",
              "   ' 0',\n",
              "   ' 0',\n",
              "   ' 0',\n",
              "   ' 22.14829']])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Viz"
      ],
      "metadata": {
        "id": "5pN0YLH9cOp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"data/\"\n",
        "data = pd.read_csv('data/driving_log.csv')\n",
        "data.head()\n",
        "# data.iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "_ulMCNIPcVEj",
        "outputId": "e9f65878-8cd1-4314-b7c4-bbd841356964"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   center  \\\n",
              "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
              "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
              "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
              "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
              "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
              "\n",
              "                                    left  \\\n",
              "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
              "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
              "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
              "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
              "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
              "\n",
              "                                    right  steering  throttle  brake  \\\n",
              "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
              "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
              "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
              "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
              "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
              "\n",
              "       speed  \n",
              "0  22.148290  \n",
              "1  21.879630  \n",
              "2   1.453011  \n",
              "3   1.438419  \n",
              "4   1.418236  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44d07ea5-718e-42b5-8164-736675ca1959\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>center</th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>steering</th>\n",
              "      <th>throttle</th>\n",
              "      <th>brake</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.148290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.879630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.453011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.438419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
              "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
              "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.418236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44d07ea5-718e-42b5-8164-736675ca1959')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44d07ea5-718e-42b5-8164-736675ca1959 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44d07ea5-718e-42b5-8164-736675ca1959');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbc88eec-c8c3-477f-aebe-fae0a1970fd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbc88eec-c8c3-477f-aebe-fae0a1970fd3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbc88eec-c8c3-477f-aebe-fae0a1970fd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data[\"steering\"].describe()\n",
        "# plt.hist(data[\"steering\"])\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style = 'whitegrid')\n",
        "plt.figure(figsize = (15,9))\n",
        "sns.histplot(data[\"steering\"], bins = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "NE4hLOZvcnXM",
        "outputId": "d878a86f-e07c-4d58-8c03-2e1c83400f09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='steering', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yCutCnxtex5O",
        "outputId": "fa8b17c2-3a5b-4ba5-eede-7fecf92b01f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing and Augmentation\n",
        "\n",
        "[reference](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py)"
      ],
      "metadata": {
        "id": "s1L-V-fff_-c"
      }
    },
    {
      "metadata": {
        "id": "UsFgB26hSmWN"
      },
      "cell_type": "code",
      "source": [
        "from torchvision import models,transforms,datasets\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.io import read_image\n",
        "\n",
        "def path_to_img(img_path):\n",
        "  img_path = str(img_path)\n",
        "  img = read_image(f'data/IMG/{img_path.split(\"/\")[-1]}')\n",
        "  return img\n",
        "\n",
        "def cropping(img):\n",
        "  img = img[60:140, :] #picture-level\n",
        "  # img = img[: ,60:140, :] # batch-level [RGB0:3, row_from:to, col_from: to]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformations = v2.Compose([\n",
        "    v2.ToTensor(),  # Convert to tensor, only needed if you had a PIL image\n",
        "    # v2.ToDtype(torch.uint8, scale=True),  # input are already uint8\n",
        "    v2.Resize(size=(200,60), antialias=True), # v2.RandomResizedCrop(size=(224, 224), antialias=True)\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True)  # Normalize expects float input\n",
        "    # v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "# antialias=True to smooth the edges of images or graphics to reduce aliasing artifacts, such as jagged edges or flickering\n",
        "\n",
        "\n",
        "'''\n",
        "import torchvision.transforms as transforms\n",
        "transformations = transforms.Compose([transforms.Lambda(lambda x: (x / 255.0) - 0.5)])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "9xVkbc5ekuG6",
        "outputId": "e2a0aa3c-03b7-4a51-b684-ce678abe4a26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport torchvision.transforms as transforms\\ntransformations = transforms.Compose([transforms.Lambda(lambda x: (x / 255.0) - 0.5)])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to display images\n",
        "# overwrite plt.imshow\n",
        "def imshow(img, title=None, normalization = False):\n",
        "  img = img.numpy().transpose((1, 2, 0))\n",
        "  if normalization:\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = std * img + mean\n",
        "  img = np.clip(img,0,1)\n",
        "  # Clipping input data to the valid range for imshow with RGB data\n",
        "  # [0,1] for floats or [0,255] for integers\n",
        "  plt.imshow(img)\n",
        "  if title is not None:\n",
        "    plt.title(title)"
      ],
      "metadata": {
        "id": "eAOeB0Z4HMge"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sum it up\n",
        "def random_flip(img, angle):\n",
        "  if np.random.rand() < 0.5:\n",
        "    img = cv2.flip(img, 1)\n",
        "    angle = -angle\n",
        "  return img, angle\n",
        "\n",
        "def random_augment(img, angle):\n",
        "  v2.RandomHorizontalFlip(p=0.5)\n",
        "  if np.random.rand() < 0.5:\n",
        "    jitter = v2.ColorJitter(brightness=.5, hue=.3)\n",
        "    img = jitter(img)\n",
        "  if np.random.rand() < 0.5:\n",
        "    img, angle = random_flip(img, angle)\n",
        "  if np.random.rand() < 0.5:\n",
        "    blurrer = v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))\n",
        "    img = blurrer(img)\n",
        "  return img, angle"
      ],
      "metadata": {
        "id": "0Xo1s53gPX40"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Reading, Loading and Batching"
      ],
      "metadata": {
        "id": "Ov3TX0J-mvVa"
      }
    },
    {
      "metadata": {
        "id": "kssJYBj_RrOR"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CarImageDataset(Dataset):\n",
        "    def __init__(self, samples, transform = None, augment=None):\n",
        "      self.samples = samples\n",
        "      self.transform = transform # function default to = None, not = False\n",
        "      self.augment = augment\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # get a batch\n",
        "      batch_samples = self.samples[index]\n",
        "      # read-in Y\n",
        "      steering_angle = float(batch_samples[3])\n",
        "      # read-in X\n",
        "      center_img, left_img, right_img = batch_samples[:3]\n",
        "      # img_path to img\n",
        "      center_img, left_img, right_img = path_to_img(center_img), path_to_img(left_img),path_to_img(right_img)\n",
        "      # randomly augment X\n",
        "      if self.augment:\n",
        "          center_img,angle_center = random_augment(center_img, steering_angle)\n",
        "          left_img,angle_left = random_augment(left_img, steering_angle + 0.4)\n",
        "          right_img,angle_right = random_augment(right_img, steering_angle - 0.4 )\n",
        "      else:\n",
        "        angle_center = steering_angle\n",
        "        angle_left = steering_angle + 0.4\n",
        "        angle_right = steering_angle - 0.4\n",
        "      # cropping\n",
        "      center_img, left_img, right_img = cropping(center_img), cropping(left_img), cropping(right_img)\n",
        "      # transform\n",
        "      center_img, left_img, right_img = self.transform(center_img), self.transform(left_img), self.transform(right_img)\n",
        "      return (center_img, angle_center), (left_img, angle_left), (right_img, angle_right)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.samples)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fr1YzfF3YQtj"
      },
      "cell_type": "code",
      "source": [
        "dset_train = CarImageDataset(train_samples, transform = transformations)\n",
        "loader_train = DataLoader(dset_train, batch_size=32, shuffle=True, num_workers=6)\n",
        "# params = {'batch_size': 32, 'shuffle': True, 'num_workers': 4}\n",
        "# loader_train = data.DataLoader(dset_train, **params)\n",
        "\n",
        "dset_valid = CarImageDataset(validation_samples, transform = transformations)\n",
        "loader_valid = DataLoader(dset_valid, batch_size=32, shuffle=False, num_workers=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get a batch for testing and plotting"
      ],
      "metadata": {
        "id": "UBySz0iGHTtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a batch for plotting\n",
        "(center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right) = next(iter(loader_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "LrpQHWQ5XVJR",
        "outputId": "81d40b60-48bc-4130-c2bc-1020ce544aa3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-6246a7cbaedf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get a batch for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mcenter_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteering_angle_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteering_angle_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mright_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteering_angle_right\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-26-4f403043cc7c>\", line 18, in __getitem__\n    center_img, left_img, right_img = path_to_img(center_img), path_to_img(left_img),path_to_img(right_img)\n  File \"<ipython-input-25-7ebbe52c099e>\", line 7, in path_to_img\n    img = read_image(f'data/IMG/{img_path.split(\"/\")[-1]}')\n  File \"/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\", line 258, in read_image\n    data = read_file(path)\n  File \"/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\", line 52, in read_file\n    data = torch.ops.image.read_file(path)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 692, in __call__\n    return self._op(*args, **kwargs or {})\nRuntimeError: [Errno 2] No such file or directory: 'data/IMG/center_2016_12_01_13_35_56_419.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(center_img[0])"
      ],
      "metadata": {
        "id": "huK-vDDYY_fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(center_img[0][: ,60:140, :])"
      ],
      "metadata": {
        "id": "IjGbU9olSAt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "center_img.shape, center_img[0].shape\n",
        "# [batch_size, RGB, H, W]\n",
        "# (3 x H x W)"
      ],
      "metadata": {
        "id": "-foF3ZgkGfzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the batch of images\n",
        "for i in range(len(center_img)-60):\n",
        "    # Display Center Image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    imshow(center_img[i], title=\"Center Image\")\n",
        "\n",
        "    # Display Left Image\n",
        "    plt.subplot(1, 3, 2)\n",
        "    imshow(left_img[i], title=\"Left Image\")\n",
        "\n",
        "    # Display Right Image\n",
        "    plt.subplot(1, 3, 3)\n",
        "    imshow(right_img[i], title=\"Right Image\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oT8sGQ2FGdM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        "\n",
        " ### NVIDIA Model\n",
        "    Image normalization to avoid saturation and make gradients work better.\n",
        "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "    Drop out (0.5)\n",
        "    Fully connected: neurons: 100, activation: ELU\n",
        "    Fully connected: neurons: 50, activation: ELU\n",
        "    Fully connected: neurons: 10, activation: ELU\n",
        "    Fully connected: neurons: 1 (output)\n",
        "    \n",
        "    the convolution layers are meant to handle feature engineering\n",
        "    the fully connected layer for predicting the steering angle.\n",
        "    dropout avoids overfitting\n",
        "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem.\n",
        "    \n",
        "### Simple Model\n",
        "\n",
        "```\n",
        "  (module): CarSimpleModel (\n",
        "    (conv_layers): Sequential (\n",
        "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
        "      (1): ELU (alpha=1.0)\n",
        "      (2): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
        "      (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
        "      (4): Dropout (p = 0.25)\n",
        "    )\n",
        "    (linear_layers): Sequential (\n",
        "      (0): Linear (3648 -> 50)\n",
        "      (1): ELU (alpha=1.0)\n",
        "      (2): Linear (50 -> 10)\n",
        "      (3): Linear (10 -> 1)\n",
        "    )\n",
        "  )\n",
        "```"
      ],
      "metadata": {
        "id": "UD9npqmLm3Fw"
      }
    },
    {
      "metadata": {
        "id": "wIH_nTixZzK8"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NetworkDense(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NetworkDense, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 36, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(36, 48, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(48, 64, 3),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(64, 64, 3),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=64 * 2 * 33, out_features=100),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=100, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class NetworkLight(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NetworkLight, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 48, 3, stride=2),\n",
        "            nn.MaxPool2d(4, stride=4),\n",
        "            nn.Dropout(p=0.25)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=48*4*19, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJDC80BOa-uQ"
      },
      "cell_type": "code",
      "source": [
        "model = NetworkLight()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation Loop"
      ],
      "metadata": {
        "id": "01tHPY6wvBCc"
      }
    },
    {
      "metadata": {
        "id": "lKjZkt4lbJxB"
      },
      "cell_type": "code",
      "source": [
        "max_epochs = 5\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define lists to track train and valid loss\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "def to_device(datas, device):\n",
        "    imgs, angles = datas\n",
        "    return imgs.float().to(device), angles.float().to(device)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    model.to(device)\n",
        "\n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for local_batch, (centers, lefts, rights) in enumerate(loader_train):\n",
        "        # Transfer to GPU\n",
        "        centers, lefts, rights = to_device(centers, device), to_device(lefts, device), to_device(rights, device)\n",
        "\n",
        "        # Model computations\n",
        "        optimizer.zero_grad()\n",
        "        for data in [centers, lefts, rights]:\n",
        "            imgs, angles = data\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, angles.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        if local_batch % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{max_epochs}], Batch [{local_batch+1}], Train Loss: {train_loss/((local_batch+1)*3):.3f}')\n",
        "\n",
        "    # Track train loss for the epoch\n",
        "    avg_train_loss = train_loss / ((local_batch + 1) * 3)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for local_batch, (centers, lefts, rights) in enumerate(loader_valid):\n",
        "            # Transfer to GPU\n",
        "            centers, lefts, rights = to_device(centers, device), to_device(lefts, device), to_device(rights, device)\n",
        "\n",
        "            # Model computations\n",
        "            optimizer.zero_grad()\n",
        "            for data in [centers, lefts, rights]:\n",
        "                imgs, angles = data\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, angles.unsqueeze(1))\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "            avg_valid_loss = valid_loss / (local_batch + 1)\n",
        "            if local_batch % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{max_epochs}], Validation Batch [{local_batch+1}], Valid Loss: {avg_valid_loss:.3f}')\n",
        "\n",
        "    # Track validation loss for the epoch\n",
        "    valid_losses.append(avg_valid_loss)\n",
        "\n",
        "# Print the final train and validation losses\n",
        "print(\"Final Train Loss:\", train_losses)\n",
        "print(\"Final Validation Loss:\", valid_losses)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Errors"
      ],
      "metadata": {
        "id": "SeHZCPr3vrNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "epochs = range(1, max_epochs + 1)\n",
        "\n",
        "\n",
        "plt.plot(epochs, train_losses, label='Train Loss')\n",
        "plt.plot(epochs, valid_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ok4ZY4o-vuNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model to disk"
      ],
      "metadata": {
        "id": "pCq6FEtTvnvr"
      }
    },
    {
      "metadata": {
        "id": "8jH0DLUi8fC_"
      },
      "cell_type": "code",
      "source": [
        "state = {\n",
        "        'model': model.module if device == 'cuda' else model,\n",
        "        }\n",
        "\n",
        "torch.save(state, 'model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}